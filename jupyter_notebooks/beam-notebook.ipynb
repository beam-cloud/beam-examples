{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533484ad",
   "metadata": {},
   "source": [
    "# Run Beam in a Jupyter Notebook\n",
    "\n",
    "The first step is to install the Beam SDK in the notebook and register your auth token.\n",
    "\n",
    "You can find your auth token on platform.beam.cloud once you've signed up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install beam-client\n",
    "!pip install beam-client\n",
    "\n",
    "# Import the Beam client\n",
    "import beam\n",
    "\n",
    "# Add your Beam API key\n",
    "!beam configure default --token [YOUR-BEAM-TOKEN]\n",
    "\n",
    "!beam config select default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3373a127",
   "metadata": {},
   "source": [
    "# Reading Local Files\n",
    "\n",
    "Any files in the same directory as the notebook instance will be available to run on Beam.\n",
    "\n",
    "In the example below, we'll load local model weights into the remote function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851fc5b6-5d0a-4f13-9efe-af24656bc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam import function, Image\n",
    "\n",
    "# Load local model weights\n",
    "WEIGHTS_PATH = \"./weights.pth\"\n",
    "\n",
    "@function(cpu=2, memory=\"1Gi\", image=Image(python_packages=[\"torch\"]))\n",
    "def handler():\n",
    "    import torch\n",
    "    # Load model weights from a local file\n",
    "    model = torch.load(WEIGHTS_PATH)\n",
    "    model.eval()\n",
    "    \n",
    "    return {\"success\": \"true\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f1004-bbea-45ce-9041-c728720b402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell on remotely on Beam\n",
    "handler.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db6b64",
   "metadata": {},
   "source": [
    "# Adding GPU Acceleration\n",
    "\n",
    "You can run any function on a powerful cloud GPU by adding a `gpu` argument to your Beam decorator. Let's update our code above to run on an A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d923ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam import function, Image\n",
    "\n",
    "\n",
    "# Runs on an A100-40 GPU in the cloud\n",
    "@function(gpu=\"A100-40\", cpu=4, memory=\"32Gi\", image=Image(python_packages=[\"torch\"]))\n",
    "def handler():\n",
    "    import subprocess\n",
    "    \n",
    "    # Print the available GPU drivers \n",
    "    print(subprocess.check_output([\"nvidia-smi\"], shell=True))\n",
    "\n",
    "    return {\"gpu\":\"true\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11302b0",
   "metadata": {},
   "source": [
    "# Listing Tasks and Running CLI Commands\n",
    "\n",
    "Beam has CLI management commands you can run from the notebook. \n",
    "\n",
    "Some common commands:\n",
    "\n",
    "```\n",
    "# List all tasks you ran\n",
    "beam task list\n",
    "\n",
    "# List all containers running \n",
    "beam container list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tasks you ran\n",
    "!beam task list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
